{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pytensor\n",
    "import pytensor.tensor as pt\n",
    "import pymc as pm\n",
    "\n",
    "from pytensor.tensor.slinalg import cholesky\n",
    "from pytensor.graph import FunctionGraph\n",
    "from pytensor.graph.rewriting.basic import node_rewriter, in2out\n",
    "from pytensor.tensor.rewriting.basic import register_canonicalize\n",
    "from pytensor.graph.op import Op, Apply\n",
    "from pymc.gp.util import stabilize\n",
    "from pymc.logprob.abstract import _logprob, _get_measurable_outputs, MeasurableVariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cov(Op):\n",
    "\n",
    "    __props__ = (\"fn\",)\n",
    "\n",
    "    def __init__(self, fn):\n",
    "        self.fn = fn\n",
    "\n",
    "    def make_node(self, ls):\n",
    "        ls = pt.as_tensor(ls)\n",
    "        out = pt.matrix(shape=(None, None))\n",
    "\n",
    "        return Apply(self, [ls], [out])\n",
    "\n",
    "    def __call__(self, ls=1.0):\n",
    "        return super().__call__(ls)\n",
    "\n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        raise NotImplementedError(\"You should convert Cov into a TensorVariable expression!\")\n",
    "\n",
    "    def do_constant_folding(self, fgraph, node):\n",
    "        return False\n",
    "\n",
    "\n",
    "class GP(Op):\n",
    "\n",
    "    __props__ = (\"approx\",)\n",
    "\n",
    "    def __init__(self, approx):\n",
    "        self.approx = approx\n",
    "\n",
    "    def make_node(self, mean, cov):\n",
    "        mean = pt.as_tensor(mean)\n",
    "        cov = pt.as_tensor(cov)\n",
    "\n",
    "        if not (cov.owner and isinstance(cov.owner.op, Cov)):\n",
    "            raise ValueError(\"Second argument should be a Cov output.\")\n",
    "\n",
    "        out = pt.vector(shape=(None,))\n",
    "\n",
    "        return Apply(self, [mean, cov], [out])\n",
    "\n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        raise NotImplementedError(\"You cannot evaluate a GP, not enough RAM in the Universe.\")\n",
    "\n",
    "    def do_constant_folding(self, fgraph, node):\n",
    "        return False\n",
    "\n",
    "\n",
    "class PriorFromGP(Op):\n",
    "    \"\"\"This Op will be replaced by the right MvNormal.\"\"\"\n",
    "\n",
    "    def make_node(self, gp, x, rng):\n",
    "        gp = pt.as_tensor(gp)\n",
    "        if not (gp.owner and isinstance(gp.owner.op, GP)):\n",
    "            raise ValueError(\"First argument should be a GP output.\")\n",
    "\n",
    "        # TODO: Assert RNG has the right type\n",
    "        x = pt.as_tensor(x)\n",
    "        out = x.type()\n",
    "\n",
    "        return Apply(self, [gp, x, rng], [out])\n",
    "\n",
    "    def __call__(self, gp, x, rng=None):\n",
    "        if rng is None:\n",
    "            rng = pytensor.shared(np.random.default_rng())\n",
    "        return super().__call__(gp, x, rng)\n",
    "\n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        raise NotImplementedError(\"You should convert PriorFromGP into a MvNormal!\")\n",
    "\n",
    "    def do_constant_folding(self, fgraph, node):\n",
    "        return False\n",
    "\n",
    "\n",
    "cov_op = Cov(fn=pm.gp.cov.ExpQuad)\n",
    "gp_op = GP(\"vanilla\")\n",
    "# SymbolicRandomVariable.register(type(gp_op))\n",
    "prior_from_gp = PriorFromGP()\n",
    "\n",
    "MeasurableVariable.register(type(prior_from_gp))\n",
    "\n",
    "\n",
    "@_get_measurable_outputs.register(type(prior_from_gp))\n",
    "def gp_measurable_outputs(op, node):\n",
    "    return node.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PriorFromGP [id A] <TensorType(float64, (50,))>\n",
      " |GP{approx='vanilla'} [id B] <TensorType(float64, (?,))>\n",
      " | |mean [id C] <TensorType(float64, (?,))>\n",
      " | |Cov{fn=<class 'pymc.gp.cov.ExpQuad'>} [id D] <TensorType(float64, (?, ?))>\n",
      " |   |ls [id E] <TensorType(float64, ())>\n",
      " |x [id F] <TensorType(float64, (50,))>\n",
      " |RandomGeneratorSharedVariable(<Generator(PCG64) at 0x7FE619D9DD20>) [id G] <RandomGeneratorType>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fe6947d53c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = pt.vector(\"mean\")\n",
    "x = pt.vector(\"x\", shape=(50,))\n",
    "ls = pt.scalar(\"ls\")\n",
    "\n",
    "cov = cov_op(ls)\n",
    "gp = gp_op(mean, cov)\n",
    "f = prior_from_gp(gp, x)\n",
    "pytensor.dprint(f, print_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PriorFromGP.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymc.logprob.abstract import get_measurable_outputs\n",
    "\n",
    "get_measurable_outputs(f.owner.op, f.owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can only run once\n",
    "@register_canonicalize\n",
    "@node_rewriter(tracks=[PriorFromGP])\n",
    "def prior_from_gp_to_mvnormal(fgraph: FunctionGraph, node: Apply):\n",
    "    out = node.outputs[0]\n",
    "    gp, X, rng = node.inputs\n",
    "    # TODO: Check GP is still a GP Op\n",
    "    mean, cov = gp.owner.inputs\n",
    "\n",
    "    if gp.owner.op.approx != \"vanilla\":\n",
    "        return False\n",
    "\n",
    "    # Materialize cov\n",
    "    ls = cov.owner.inputs[0]\n",
    "    cov = cov.owner.op.fn(input_dim=1, ls=ls).full(X[:, None])\n",
    "\n",
    "    size = pt.shape(X)[0]\n",
    "    fgraph.add_input(rng)\n",
    "\n",
    "    # TODO: Give names\n",
    "    L = cholesky(stabilize(cov))\n",
    "    #     L.name = \"L\"\n",
    "    v = pm.Normal.dist(0, 1, size=size, rng=rng)\n",
    "    f = mean + pt.dot(L, v)\n",
    "\n",
    "    return [f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FromFunctionNodeRewriter(<function prior_from_gp_to_mvnormal at 0x7fe617259510>, [<class '__main__.PriorFromGP'>], ())"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_from_gp_to_mvnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = FunctionGraph(outputs=[f], clone=False)\n",
    "[out] = prior_from_gp_to_mvnormal.transform(fg, fg.outputs[0].owner)\n",
    "# pytensor.dprint(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_logprob.register(PriorFromGP)\n",
    "def prior_gp_logprob(op, values, gp, X, rng, **kwargs):\n",
    "    [value] = values\n",
    "\n",
    "    # TODO: Check GP is still a GP Op\n",
    "    mean, cov = gp.owner.inputs\n",
    "\n",
    "    if gp.owner.op.approx != \"vanilla\":\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    # Materialize cov\n",
    "    ls = cov.owner.inputs[0]\n",
    "    cov = cov.owner.op.fn(input_dim=1, ls=ls).full(X[:, None])\n",
    "\n",
    "    f = pm.MvNormal.dist(mu=mean, cov=stabilize(cov))\n",
    "    return pm.logp(f, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ls ~ Gamma(4, f()), f]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with pm.Model() as m:\n",
    "    mean = pt.zeros(())\n",
    "    x = pm.ConstantData(\"x\", np.linspace(0, 10, 20))\n",
    "    ls = pm.Gamma(\"ls\", alpha=4, beta=1)\n",
    "\n",
    "    cov = cov_op(ls)\n",
    "    gp = gp_op(mean, cov)\n",
    "    f = prior_from_gp(gp, x)\n",
    "\n",
    "    m.register_rv(f, name=\"f\", initval=np.zeros(20))\n",
    "\n",
    "m.basic_RVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ls_log__': array(1.38629436),\n",
       " 'f': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip = m.initial_point()\n",
    "ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(78.72276943)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.compile_logp()(m.initial_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [f, ls]\n"
     ]
    }
   ],
   "source": [
    "with m:\n",
    "    idata = pm.sample_prior_predictive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idata.prior[\"f\"].mean((\"chain\", \"draw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Check{posdef}.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.logp(f, np.ones(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__logp"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.logp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [ls, f]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='221' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      2.76% [221/8000 01:11&lt;41:50 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with m:\n",
    "    idata = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytensor.dprint(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.eval({mean: np.ones(50), x: np.linspace(0, 10, 50), ls: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "pymc_experimental",
   "language": "python",
   "name": "pymc_experimental"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
